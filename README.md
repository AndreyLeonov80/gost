# gost
**ИИ для работы с рассуждениями и QA по ГОСТам**

**Задача** https://habr.com/ru/companies/omk-it/articles/850434/

**Верхнеуровневая текущая и стратегическая "Архитекура ИИ решения"**

![Архитектура ИИ решения](https://raw.githubusercontent.com/AndreyLeonov80/gost/refs/heads/main/back/architecture/%D0%92%D0%B5%D1%80%D1%85%D0%BD%D0%B5%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D0%B0%D1%8F%20%D1%82%D0%B5%D0%BA%D1%83%D1%89%D0%B0%D1%8F%20%D0%B8%20%D1%81%D1%82%D1%80%D0%B0%D1%82%D0%B5%D0%B3%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F%20%22%D0%90%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%83%D1%80%D0%B0%20%D0%98%D0%98%20%D1%80%D0%B5%D1%88%D0%B5%D0%BD%D0%B8%D1%8F%22.png)

**Методология на примере ГОСТ 14637-89.pdf.**

1. Сегментация и очистка PDF-файла

       Разделение документа на информационные блоки и таблицы.
       Очистка данных от лишней информации.
       Результат сохраняется в: gost/back/py/datasource/infoblocks/ГОСТ 14637-89 - null.txt

2. Генерация пакета QA через LLM и промт-инжиниринг
        
       Файлы находятся в директории: gost/back/py/datasource

4. Обучение модели 

   Выполнить
  
       pip install -r requirements.txt
   
   В gost/back/py/train.py
  
       указать полный путь с json файлами в директории datasource например
       base_path = '/Users/aiapi/Desktop/prj_omk/omkllm/291024/gost/back/py'
   
       указать модель обучения которая сохранится в файл self.model_path = 'trained_model.pkl' (или trained_model_promt_template.pkl)

   Запустить gost/back/py/train.py для обучения модели на основе QA данных
	
       логи
       qa_model_20241030_115625.log для модели trained_model.pkl
       trained_model_promt_template.pkl.log для модели trained_model_promt_template.pkl (или trained_model_promt_template.pkl)

4. Проверяем модель на copilot gost/back/py/copilot.py
   
       указать полный путь для pkl модели например
       base_path = '/Users/aiapi/Desktop/prj_omk/omkllm/291024/gost/back/py'
   
       указать pkl модель self.model_path = 'trained_model.pkl' (или trained_model_promt_template.pkl)

**Варианты LLM:**
  - платные api gpt4 https://platform.openai.com/docs/concepts
  - платные api claude https://docs.anthropic.com/en/home
  - платные c большим выбором моделей без своего GPU https://openrouter.ai
  - локальные LLM например через сервер настроенный в https://lmstudio.ai
  - аренда gpu например https://immers.cloud

Тюнинг параметров LLM от которых зависити результат - могу описать по запросу.

**Демо-сервер на Flutter:**
     
Приложение: https://appomk.frontback.tech

Видео демонстрация: https://cloud.mail.ru/public/K75R/Rc9Jq5pGZ

Модели и результаты:
- **trained_model.pkl** (обучена на **ГОСТ 14637-89.pdf** через гиперсегментацию ГОСТа на инфоблоки/таблицы)
  
  Видео https://cloud.mail.ru/public/jSCk/txkSYpVw7

      промт gost/back/py/datasource/infoblocks/promts.txt
      QA обучающая выборка:
       - gost/back/py/datasource/infoblocks
       - gost/back/py/datasource/tables

- **trained_model_promt_template.pkl** (обучена на **ГОСТ 14637-89.pdf** через вариации промта "Какие границы для испытания на временное сопротивление для широкополосного проката, марка стали Ст3сп, толщина проката 20, категория 5 для ГОСТ 14637-89?")
    
      промт gost/back/py/datasource/infoblocks2/gen-llm plk promt.txt
      QA обучающая выборка gost/back/py/datasource/infoblocks2/89-1.json

# Дополнительные методы улучшения модели MaterialsQAModel

## Методы обработки векторных представлений

### transform_embeddings()
- Контекстные эмбеддинги на основе трансформеров
- Снижение размерности (UMAP/t-SNE)
- Поддержка многоязычных эмбеддингов
- Обработка внесловарных токенов

### optimize_vectorizer_parameters()
- Настройка параметров TF-IDF (`max_features`, `ngram_range`, `min_df`)

        TF-IDF (Term Frequency-Inverse Document Frequency) параметры:
        
        1. `max_features`: 
           - Ограничивает размер словаря
           - Пример: max_features=1000 оставит только 1000 самых важных слов
        
        2. `ngram_range`: 
           - Определяет, сколько слов рассматривать вместе
           - (1,1): отдельные слова ["сталь", "прокат"]
           - (1,2): слова и пары ["сталь", "прокат", "стальной_прокат"]
        
        3. `min_df`:
           - Минимальная частота появления термина в документах
           - min_df=2: игнорировать слова, встречающиеся реже 2 раз
           - Помогает убрать редкие/опечатки
        
        Эти параметры влияют на качество векторизации текста и точность поиска похожих вопросов.

- Оптимизация размера словаря
- Отбор признаков
- Экспериментальная настройка для улучшения точности

        Экспериментальная настройка включает:
        
        1. Тестирование разных комбинаций параметров:
             - Размер словаря
             - Длина n-грамм
             - Пороги частот
        
        2. Процесс оптимизации:
             - Разделение данных на тренировочную/тестовую выборки
             - Перебор параметров
             - Измерение метрик качества для каждой конфигурации
             - Выбор лучшей комбинации параметров
        
        3. Критерии:
             - Точность ответов
             - Скорость работы
             - Потребление памяти

## Методы работы с данными

### augment_training_data()
- Генерация вариаций вопросов

        Генерация вариаций вопросов включает создание разных формулировок одного и того же вопроса:
        
        1. Методы генерации:
           - Синонимическая замена
           - Изменение структуры предложения
           - Добавление/удаление уточняющих слов
           - Использование языковых моделей (GPT, T5)
        
        2. Пример вариаций:
           Исходный: "Какая толщина проката для стали марки Ст3пс?"
           Варианты:
           - "Для Ст3пс какой должна быть толщина проката?"
           - "Укажите толщину проката стали Ст3пс"
           - "Какой толщины должен быть прокат из стали марки Ст3пс?"

- Обратный перевод для создания парафразов

        Обратный перевод (back translation) - это техника создания парафразов через перевод текста:
        
        1. Процесс:
           - Исходный текст → перевод на другой язык → обратный перевод на исходный язык
        
        2. Пример:
           Исходный: "Какая толщина проката для стали марки Ст3пс?"
             → English: "What is the thickness of rolled steel grade St3ps?"
             → Обратно: "Какова толщина стального проката марки Ст3пс?"
        
        3. Преимущества:
           - Сохраняет смысл
           - Создает естественные формулировки
           - Автоматизируется через API переводчиков

- Использование T5/GPT для перефразирования

        T5/GPT для перефразирования - это использование языковых моделей для создания вариаций текста:
        
        1. T5 (Text-to-Text Transfer Transformer):
           - Указываем команду: "paraphrase: [текст]"
           - Модель генерирует перефразированные версии
        
        2. GPT:
           - Задаем промпт: "Перефразируй вопрос разными способами"
           - Получаем несколько вариантов
        
        3. Пример:
           Исходный: "Какие требования к прочности стали?"
           GPT варианты:
            - "Какими должны быть прочностные характеристики стали?"
            - "Каковы нормативы по прочности для стали?"
            - "Какие показатели прочности установлены для стали?"

- Сохранение семантики ответов

        Сохранение семантики ответов - это обеспечение того, чтобы смысл ответа оставался неизменным при различных преобразованиях:
      
        1. Проверки:
           - Соответствие техническим терминам
           - Сохранение числовых значений
           - Неизменность условий и ограничений
      
        2. Пример:
           Исходный: "Прочность стали на разрыв 500 МПа при 20°C"
           Должен сохранять:
           - Значение (500 МПа)
           - Условие (при 20°C)
           - Тип испытания (на разрыв)
      
        3. Важные аспекты:
           - Точность технических данных
           - Корректность единиц измерения
           - Сохранение причинно-следственных связей

### expand_question_variants()
- Создание парафразов вопросов

        Парафраз вопросов - это переформулирование одного и того же вопроса разными способами, сохраняя его смысл. Например:
        
        Исходный вопрос: "Какая температура плавления стали?"
        
        Парафразы:
        - "При какой температуре сталь начинает плавиться?"
        - "Точка плавления стали - это сколько градусов?"
        - "Какой температурный порог нужен для расплавления стали?"

        Это помогает модели лучше понимать разные формулировки одного запроса и давать корректные ответы независимо от того, как задан вопрос.

- Улучшение понимания различных формулировок

        Улучшение понимания различных формулировок включает:
      
        1. Технические аспекты:
           - Распознавание синонимов
           - Учет профессионального сленга
           - Обработка разного порядка слов
      
        2. Пример обработки:
           "Предел прочности стали"
           = "Временное сопротивление стали"
           = "Максимальное напряжение разрушения стали"
           = "Разрушающее напряжение стали"
      
        3. Преимущества:
           - Точные ответы на разные формулировки
           - Понимание профессиональной терминологии
           - Гибкость в обработке запросов

- Расширение обучающей выборки

### rank_data_sources()
- Ранжирование источников по точности
- Оценка надежности источников
- Приоритизация качественных данных

## Методы оценки качества

### calculate_bert_similarity()
- Предобученные BERT эмбеддинги

      BERT эмбеддинги (предварительно обученные) - это векторные представления слов, полученные после обучения модели BERT на больших текстовых корпусах:
      
      1. Характеристики:
         - Учитывают контекст слова
         - Разные вектора для многозначных слов
         - Содержат семантическую информацию
      
      2. Пример:
         "сталь" в разных контекстах:
         - "закаленная сталь" → вектор отражает технические свойства
         - "стальные нервы" → вектор отражает переносное значение
      
      3. Преимущества:
         - Глубокое понимание контекста
         - Высокая точность сравнения текстов
         - Работа с техническими терминами

- Расчет схожести на основе внимания

          Расчет схожести на основе внимания (attention-based similarity) - это метод из архитектуры трансформеров, где:
        
          1. Каждому слову/токену присваивается вес важности
          2. Модель "обращает внимание" на разные части текста с разной интенсивностью
          3. При сравнении двух текстов учитываются не только сами слова, но и контекст их использования
          4. Веса внимания помогают определить, насколько похожи смыслы фраз, даже если они используют разные слова
        
          Например, вопросы "Какова прочность стали?" и "Какое максимальное напряжение выдерживает сталь?" будут определены как схожие, хотя используют разные термины.

          Attention (механизм внимания) в контексте сравнения текстов:

          1. Принцип работы:
             - Анализирует, как слова/части текста влияют друг на друга
             - Присваивает важность каждому элементу текста
             - Учитывает контекстные связи между словами

             2. Пример:
             "Какова прочность стали на разрыв?"
             ↓ механизм внимания оценивает связи ↓
             "Какое значение предела прочности у стали при растяжении?"

          Модель понимает, что это один и тот же вопрос, потому что механизм внимания определяет ключевые смысловые связи между концепциями "прочность-предел прочности" и "разрыв-растяжение".

- Межъязыковое сравнение
- Анализ схожести на уровне токенов

        Анализ схожести на уровне токенов включает:
      
        1. Разбиение текста на токены:
           - Слова: "прочность" → токен
           - Части слов: "сверхпрочный" → "сверх" + "прочный"
           - Технические термины: "марка_стали" как единый токен
      
        2. Сравнение:
           - Прямые совпадения токенов
           - Морфологические варианты
           - Специальные символы и обозначения
      
        3. Примеры сравнения:
           "Ст3сп" vs "СТ3СП" - одинаковые токены
           "прочностные" vs "прочность" - связанные токены
           "σв" vs "предел_прочности" - эквивалентные токены

### calculate_model_confidence()
- Оценка уверенности модели в ответах

      Оценка уверенности модели включает:
  
      1. Метрики уверенности:
         - Косинусное сходство векторов
         - Вероятность правильности ответа
         - Статистика встречаемости похожих вопросов
      
      2. Пример оценки:
         Вопрос: "Какая прочность стали марки Ст3сп?"
         - Высокая уверенность (>0.9): точное совпадение в базе
         - Средняя (0.5-0.9): похожие вопросы есть
         - Низкая (<0.5): нет близких совпадений
      
      3. Применение:
         - Фильтрация ненадежных ответов
         - Запрос уточнений при низкой уверенности
         - Приоритизация источников данных

  - Система подсчета баллов уверенности

        Компоненты оценки:

        Общий балл = (A + B + C + D) / 4, где:
        A: Схожесть векторов (0-1.0)
        B: Качество источника (0-1.0)
        C: Частота встречаемости (0-1.0)
        D: Контекстная релевантность (0-1.0)

        Пример расчета:
  
        Вопрос: "Требования к стали Ст3сп"
        A: Схожесть = 0.85 (высокая)
        B: Источник = 1.0 (ГОСТ)
        C: Частота = 0.7 (встречается часто)
        D: Контекст = 0.9 (точное соответствие)
        
        Итоговый балл = (0.85 + 1.0 + 0.7 + 0.9) / 4 = 0.86

- Прозрачность надежности ответов

### validate_answer_quality()
- Проверка семантической согласованности
- Валидация по базе знаний
- Оценка полноты ответов
- Выявление противоречий

### filter_low_confidence_answers()
- Фильтрация ответов с низкой уверенностью
- Предотвращение неточных ответов
- Повышение доверия пользователей

## Методы кластеризации и валидации

### optimize_question_clusters()
- Иерархическая кластеризация
- Плотностная кластеризация (DBSCAN)
- Оптимизация границ кластеров
- Динамическое обновление

### cross_validate_answers()
- K-блочная валидация
- Стратифицированная выборка
- Анализ ошибок
- Отслеживание метрик

## Методы генерации ответов

### ensemble_answer_generation()
- Взвешенное голосование
- Стекинг моделей
- Выбор по уверенности
- Динамическая настройка весов

### contextual_answer_generation()
- Учет контекста вопроса
- Анализ связанных вопросов
- Улучшение полноты ответов

## Методы анализа и адаптации

### analyze_failure_patterns()
- Отслеживание проблемных вопросов
- Категоризация ошибок
- Выявление слабых мест модели

### adaptive_training_cycle()
- Непрерывное обучение на новых данных
- Периодическое обновление модели
- Поддержание актуальности ответов

### fine_tune_on_feedback()
- Обучение на основе обратной связи
- Улучшение точности ответов
- Адаптация к пользовательским потребностям

### suggest_similar_unanswered_questions()
- Поиск похожих вопросов без ответов
- Расширение базы знаний
- Улучшение покрытия тем

## Метрики эффективности
- Точность ответов
- Время отклика
- Использование памяти
- Оценки уверенности
- Результаты кросс-валидации

## Рекомендации по интеграции
1. Поэтапное внедрение методов
2. Независимое тестирование
3. Мониторинг производительности
4. Валидация на тестовой выборке
5. Документирование конфигураций

**Алгоритмы/технологии которые есть в запасе и которые можно отдельно обсудить:**
- добавление новых вопросов в обученную модель, обновляя TF-IDF векторизацию с помощью partial_fit
- матчинг вопросов и в целом матчинг терминов
- распознавание таблиц и ячеек таблиц, если они являются графическими элементами 
- оптимизации алгоритмов
- ИИ copilot по ГОСТам для документооборота в структурах сделок
- openapi backend api
- другие
 
**Контакты:**

andrey.leonov@bimeister.com

https://t.me/aidialog

**О архитекторе и разработчике:**

https://codeboost.ru/about